{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T10:58:53.998297Z",
     "start_time": "2025-08-19T10:58:50.333970Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sympy.printing.pytorch import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from generator import Generator, initialize_weights\n",
    "from discriminator import Discriminator\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torchvision.transforms import Compose, Resize, ToTensor"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniilogorodnikov/PycharmProjects/Text2Image/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:47.507958Z",
     "start_time": "2025-08-19T10:58:54.002490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset('poloclub/diffusiondb', '2m_random_10k')\n",
    "model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)"
   ],
   "id": "c6456c371e9b7e93",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniilogorodnikov/PycharmProjects/Text2Image/.venv/lib/python3.13/site-packages/datasets/load.py:1429: FutureWarning: The repository for poloclub/diffusiondb contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/poloclub/diffusiondb\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading data: 100%|██████████| 644M/644M [00:50<00:00, 12.9MB/s]    \n",
      "Downloading data: 100%|██████████| 651M/651M [00:50<00:00, 12.9MB/s]    \n",
      "Downloading data: 100%|██████████| 662M/662M [00:51<00:00, 12.8MB/s]    \n",
      "Downloading data: 100%|██████████| 599M/599M [00:46<00:00, 12.9MB/s]    \n",
      "Downloading data: 100%|██████████| 611M/611M [00:47<00:00, 12.9MB/s]    \n",
      "Downloading data: 100%|██████████| 571M/571M [00:44<00:00, 12.9MB/s]    \n",
      "Downloading data: 100%|██████████| 602M/602M [00:47<00:00, 12.7MB/s]    \n",
      "Downloading data: 100%|██████████| 571M/571M [00:44<00:00, 12.9MB/s]    \n",
      "Downloading data: 100%|██████████| 578M/578M [00:44<00:00, 12.9MB/s]    \n",
      "Downloading data: 100%|██████████| 666M/666M [00:51<00:00, 12.9MB/s]    \n",
      "Generating train split: 10000 examples [00:16, 622.50 examples/s]\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:47.526891Z",
     "start_time": "2025-08-19T11:07:47.524589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 10\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 3 #3\n",
    "EMBEDDING_SIZE = 10\n",
    "GEN_EMBEDDING_SIZE = 100\n",
    "Z_DIM = 456\n",
    "NUM_EPOCHS = 10\n",
    "FEATURE_DISC = 64\n",
    "FEATURE_GEN = 64\n",
    "CRITIC_ITER = 10\n",
    "WEIGHT_CLIP = 0.01\n",
    "LAMBDA_GP = 10"
   ],
   "id": "c868cd64088ffec9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:47.547239Z",
     "start_time": "2025-08-19T11:07:47.545033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "jitter = Compose(\n",
    "    [\n",
    "        Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def transforms(examples):\n",
    "    examples[\"image\"] = [jitter(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    examples[\"prompt\"] = [torch.from_numpy(model.encode(examples[\"prompt\"]))]\n",
    "\n",
    "    return examples"
   ],
   "id": "dacdf3b64d833d03",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.547321Z",
     "start_time": "2025-08-19T11:07:47.550006Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.set_transform(transforms)",
   "id": "cdf3049127756de7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.553102Z",
     "start_time": "2025-08-19T11:07:55.550691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_penalty(critic, labels, real, fake, device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * alpha + fake * (1 - alpha)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images, labels)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty"
   ],
   "id": "510a764da41a3239",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.558914Z",
     "start_time": "2025-08-19T11:07:55.555822Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset = dataset[\"train\"].select_columns(['image', 'prompt'])",
   "id": "d019ea19de9aa06a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.566715Z",
     "start_time": "2025-08-19T11:07:55.563638Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_dataset)",
   "id": "dc1b9bad41cdef65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.723430Z",
     "start_time": "2025-08-19T11:07:55.571524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gen = Generator(Z_DIM, CHANNELS, FEATURE_GEN, IMAGE_SIZE).to(device)\n",
    "critic = Discriminator(CHANNELS, FEATURE_DISC, IMAGE_SIZE, 768).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)"
   ],
   "id": "df330452368010bc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.728443Z",
     "start_time": "2025-08-19T11:07:55.726477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))"
   ],
   "id": "378207c93d3aa13f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.732626Z",
     "start_time": "2025-08-19T11:07:55.730629Z"
    }
   },
   "cell_type": "code",
   "source": "fixed_noise = torch.randn(1, Z_DIM, 1, 1).to(device)\n",
   "id": "bd1c5feea41e299e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.739060Z",
     "start_time": "2025-08-19T11:07:55.736237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "writer_f = SummaryWriter(f\"logs/fake\")\n",
    "writer_r = SummaryWriter(f\"logs/real\")\n",
    "step = 0"
   ],
   "id": "d8298f29ed0bccd8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.744117Z",
     "start_time": "2025-08-19T11:07:55.742124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gen.train()\n",
    "critic.train()"
   ],
   "id": "9496096e20c71224",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "  )\n",
       "  (emb): Linear(in_features=768, out_features=4096, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.757552Z",
     "start_time": "2025-08-19T11:07:55.752177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "from torchinfo import summary"
   ],
   "id": "ccf3ae35b25adf01",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.767247Z",
     "start_time": "2025-08-19T11:07:55.764729Z"
    }
   },
   "cell_type": "code",
   "source": "summary(gen)",
   "id": "b647b5ac147eecf8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Generator                                --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─ConvTranspose2d: 2-1              20,055,040\n",
       "│    └─Sequential: 2-2                   --\n",
       "│    │    └─ConvTranspose2d: 3-1         8,388,608\n",
       "│    │    └─BatchNorm2d: 3-2             1,024\n",
       "│    │    └─ReLU: 3-3                    --\n",
       "│    └─Sequential: 2-3                   --\n",
       "│    │    └─ConvTranspose2d: 3-4         2,097,152\n",
       "│    │    └─BatchNorm2d: 3-5             512\n",
       "│    │    └─ReLU: 3-6                    --\n",
       "│    └─Sequential: 2-4                   --\n",
       "│    │    └─ConvTranspose2d: 3-7         524,288\n",
       "│    │    └─BatchNorm2d: 3-8             256\n",
       "│    │    └─ReLU: 3-9                    --\n",
       "│    └─ConvTranspose2d: 2-5              6,147\n",
       "│    └─Tanh: 2-6                         --\n",
       "=================================================================\n",
       "Total params: 31,073,027\n",
       "Trainable params: 31,073,027\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:07:55.775758Z",
     "start_time": "2025-08-19T11:07:55.773666Z"
    }
   },
   "cell_type": "code",
   "source": "summary(critic)",
   "id": "b6f85a87a9e3002f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Discriminator                            --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       4,160\n",
       "│    └─LeakyReLU: 2-2                    --\n",
       "│    └─Sequential: 2-3                   --\n",
       "│    │    └─Conv2d: 3-1                  131,072\n",
       "│    │    └─InstanceNorm2d: 3-2          256\n",
       "│    │    └─LeakyReLU: 3-3               --\n",
       "│    └─Sequential: 2-4                   --\n",
       "│    │    └─Conv2d: 3-4                  524,288\n",
       "│    │    └─InstanceNorm2d: 3-5          512\n",
       "│    │    └─LeakyReLU: 3-6               --\n",
       "│    └─Sequential: 2-5                   --\n",
       "│    │    └─Conv2d: 3-7                  2,097,152\n",
       "│    │    └─InstanceNorm2d: 3-8          1,024\n",
       "│    │    └─LeakyReLU: 3-9               --\n",
       "│    └─Conv2d: 2-6                       8,193\n",
       "├─Linear: 1-2                            3,149,824\n",
       "=================================================================\n",
       "Total params: 5,916,481\n",
       "Trainable params: 5,916,481\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T11:39:02.885301Z",
     "start_time": "2025-08-19T11:07:55.786553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    for inx, data in enumerate(train_dataset):\n",
    "        real = data['image'].unsqueeze(0).to(device)\n",
    "        labels = data['prompt'].to(device)\n",
    "        current_batch_size = real.size(0)  # Get actual batch size\n",
    "\n",
    "        for _ in range(CRITIC_ITER):\n",
    "            noise = torch.randn(current_batch_size, Z_DIM, 1, 1).to(device)\n",
    "            fake = gen(noise, labels)\n",
    "            critic_real = critic(real, labels).reshape(-1)\n",
    "            critic_fake = critic(fake, labels).reshape(-1)\n",
    "            gp = gradient_penalty(critic, labels, real, fake, device=device)\n",
    "            loss_critic = (-(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp)\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "\n",
    "        # Train generator\n",
    "        out = critic(fake, labels).reshape(-1)\n",
    "        lossG = -torch.mean(out)\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if inx % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{NUM_EPOCHS}] Batch {inx}/{len(train_dataset)} \"\n",
    "                f\"Loss D: {loss_critic:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(noise, labels)\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "\n",
    "                writer_r.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                writer_f.add_image(\"Fake\", img_grid_fake, global_step=step)\n",
    "\n",
    "            step += 1"
   ],
   "id": "1ebdc0124822c3f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10] Batch 0/10000 Loss D: -20.2760, loss G: 9.1220\n",
      "Epoch [0/10] Batch 100/10000 Loss D: -20.9305, loss G: 90.1726\n",
      "Epoch [0/10] Batch 200/10000 Loss D: -12.2908, loss G: 66.3133\n",
      "Epoch [0/10] Batch 300/10000 Loss D: -37.9530, loss G: -14.9834\n",
      "Epoch [0/10] Batch 400/10000 Loss D: -40.9974, loss G: 6.2963\n",
      "Epoch [0/10] Batch 500/10000 Loss D: -47.9526, loss G: 29.1011\n",
      "Epoch [0/10] Batch 600/10000 Loss D: -59.8531, loss G: 57.6297\n",
      "Epoch [0/10] Batch 700/10000 Loss D: -31.2061, loss G: 21.3148\n",
      "Epoch [0/10] Batch 800/10000 Loss D: -40.3443, loss G: 40.9904\n",
      "Epoch [0/10] Batch 900/10000 Loss D: -41.9761, loss G: 38.4272\n",
      "Epoch [0/10] Batch 1000/10000 Loss D: -43.9387, loss G: 61.3847\n",
      "Epoch [0/10] Batch 1100/10000 Loss D: -40.7754, loss G: 9.8716\n",
      "Epoch [0/10] Batch 1200/10000 Loss D: -35.6619, loss G: 42.1238\n",
      "Epoch [0/10] Batch 1300/10000 Loss D: -42.2953, loss G: 56.5671\n",
      "Epoch [0/10] Batch 1400/10000 Loss D: -35.0694, loss G: 6.3435\n",
      "Epoch [0/10] Batch 1500/10000 Loss D: -31.9651, loss G: 67.8986\n",
      "Epoch [0/10] Batch 1600/10000 Loss D: -31.4503, loss G: 52.4398\n",
      "Epoch [0/10] Batch 1700/10000 Loss D: -35.0822, loss G: 66.4850\n",
      "Epoch [0/10] Batch 1800/10000 Loss D: -37.7816, loss G: 59.9512\n",
      "Epoch [0/10] Batch 1900/10000 Loss D: -18.8391, loss G: 73.6511\n",
      "Epoch [0/10] Batch 2000/10000 Loss D: -29.1283, loss G: 93.4182\n",
      "Epoch [0/10] Batch 2100/10000 Loss D: -39.8568, loss G: 62.2580\n",
      "Epoch [0/10] Batch 2200/10000 Loss D: -45.6726, loss G: 21.1203\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      5\u001B[39m current_batch_size = real.size(\u001B[32m0\u001B[39m)  \u001B[38;5;66;03m# Get actual batch size\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(CRITIC_ITER):\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m     noise = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrandn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent_batch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mZ_DIM\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m     fake = gen(noise, labels)\n\u001B[32m     10\u001B[39m     critic_real = critic(real, labels).reshape(-\u001B[32m1\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8aa72aa574e68bc7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
